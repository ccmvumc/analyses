import os, shutil
from glob import glob

import pandas as pd
import numpy as np
import scipy.io
import matplotlib.pyplot as plt
from matplotlib.backends.backend_pdf import PdfPages
from nilearn.glm.first_level import FirstLevelModel
from nilearn.plotting import plot_stat_map
from nilearn.plotting import plot_design_matrix
from nilearn.reporting import make_glm_report
from nilearn.datasets import fetch_atlas_schaefer_2018
from nilearn.image import load_img, math_img, new_img_like
from nilearn.masking import apply_mask

from .params import TR, CONTRASTS, CUT_COORDS, THRESHOLD, COLORMAP, VMAX, ROIS


TITLE='COG-D N-Back Task'


def _make_roi_masks(output_dir, rois):
    s200 = fetch_atlas_schaefer_2018(n_rois=200, yeo_networks=7, resolution_mm=2)
    s200_image = load_img(s200['maps'])
    s200_data = s200_image.get_fdata().astype(int)

    for r in rois:
        r_name = r['name']
        r_atlas = r['atlas']
        r_labels = np.array(r['labels'])

        if r_atlas == 'Schaefer200':
            r_mask = np.isin(s200_data, r_labels.astype(np.uint8))
            r_file = f'{output_dir}/{r_name}_mask.nii.gz'
            print(f'writing mask file:{r_file}')
            new_img_like(s200_image, r_mask).to_filename(r_file)
        else:
            print(f'atlas not supported:{r_atlas}')


def _load_events(conditions_file):
    mat = scipy.io.loadmat(conditions_file, simplify_cells=True)

    names = mat['names']
    onsets = mat['onsets']
    durations = mat['durations']

    df = pd.DataFrame([
        {'onset': onset, 'duration': dur, 'trial_type': name}
        for name, onsets_, dur in zip(names, onsets, durations)
        for onset in onsets_
    ])

    df = df.sort_values('onset').reset_index(drop=True)

    return df


def _extract_rois(bmaps, masks):
    '''Get mean of each condition betamap within each roi mask'''
    data = {}

    for b in bmaps:
        for m in masks:
            c = os.path.basename(b).split('_bmap.nii.gz')[0]
            r = os.path.basename(m).split('_mask.nii.gz')[0]
            data[f'{r}_{c}'] = _roi_mean(b, m)

    return data


def _roi_mean(image, mask):
    masked_data = apply_mask(image, mask)
    return np.mean(masked_data)


def _betas(model, conditions, output_dir):
    bmaps = []

    # Save a beta map for each event type
    for i, c in enumerate(conditions):
        bmap = model.compute_contrast(c, output_type="effect_size")
        filename = f'{output_dir}/{c}_bmap.nii.gz'
        bmap.to_filename(filename)
        bmaps.append(filename)

        # Plot
        plot_stat_map(
            bmap,
            display_mode='z',
            cut_coords=CUT_COORDS,
            title=f'{TITLE} 1st-Level beta:{c}',
        )

        # Save plot
        plt.savefig(f'{output_dir}/{c}_bmap.png')

        plt.close()

    return bmaps


def _fit_model(image_file, events):
    # Specify model with parameters set for denoised CONN images
    # https://neurostars.org/t/nilearn-glm-first-level-question/29612
    print("Fitting a GLM")
    model = FirstLevelModel(
        t_r=TR,
        hrf_model='spm',
        drift_model=None,
        signal_scaling=False,
    )

    # Estimate fit
    model = model.fit(image_file, events=events)

    return model


def _contrasts(model, contrasts, output_dir, roi_dir):
    # Compute each contrast and plot
    for i, c in enumerate(contrasts):
        cid = f'{i+1:04d}'
        print(i, cid, c)

        zmap = model.compute_contrast(c, output_type='z_score')

        zmap.to_filename(f'{output_dir}/contrast_{cid}_zmap.nii.gz')

        # Plot
        display = plot_stat_map(
            zmap,
            threshold=THRESHOLD,
            display_mode='z',
            cut_coords=CUT_COORDS,
            title=f'{TITLE} 1st-Level contrast_{cid}:{c}',
            cmap=COLORMAP,
            vmax=VMAX
        )

        for r in glob(f'{roi_dir}/*.nii.gz'):
            display.add_contours(r, levels=[0.5], colors="g")

        # Save plot
        plt.savefig(f'{output_dir}/contrast_{cid}_report.pdf')

        plt.close()


def run_first_level(image_file, conditions_file, output_dir, roi_dir):
    # Load conditions from file
    events = _load_events(conditions_file)
    print(events)

    # Fit event data to image data
    model = _fit_model(image_file, events)

    # Plot our design matrix as generated by fit_model
    design_matrix = model.design_matrices_[0]
    plot_design_matrix(design_matrix)
    plt.savefig(f'{output_dir}/design.pdf', bbox_inches='tight')

    # Plot the contrasts
    _contrasts(model, CONTRASTS, output_dir, roi_dir)

    # Save the beta maps
    conditions = design_matrix.columns.tolist()
    print(f'{conditions=}')
    bmaps = _betas(model, conditions, output_dir)

    # Extract ROI means from beta maps
    masks = glob(f'{roi_dir}/*.nii.gz')
    stats = _extract_rois(bmaps, masks)
    filename = f'{output_dir}/stats.txt'
    _write_stats(stats, filename)

    # Get the default report for same contrasts
    report = make_glm_report(model, title=TITLE, contrasts=np.array(CONTRASTS), cut_coords=CUT_COORDS)
    report.save_as_html(f'{output_dir}/glm_report.html')


def _write_stats(stats, filename):
    '''Writes a text file with key/value per line'''
    with open(filename, 'w') as f:
        for k in sorted(stats):
            f.write(f'{k}={stats[k]:.3f}\n')


def _write_subjects(subjects, filename):
    '''Writes a text file with one subject per line'''
    with open(filename, 'w') as f:
        f.write('\n'.join(subjects) + '\n')


def _run_subject(baseline_image, baseline_mat, week5_image, week5_mat, output_dir, roi_dir):
    baseline_dir = f'{output_dir}/Baseline'
    week5_dir = f'{output_dir}/Week5'

    print(f'Running first-level:Baseline:{baseline_dir}')
    os.makedirs(baseline_dir, exist_ok=True)
    run_first_level(baseline_image, baseline_mat, baseline_dir, roi_dir)

    print(f'Running first-level:Week5:{week5_dir}')
    os.makedirs(week5_dir, exist_ok=True)
    run_first_level(week5_image, week5_mat, week5_dir, roi_dir)


def main(input_dir, output_dir):
    print('making masks')
    roi_dir = f'{output_dir}/ROIS'
    os.makedirs(roi_dir, exist_ok=True)
    _make_roi_masks(roi_dir, ROIS)

    print('loading subjects')
    subjects = [x for x in os.listdir(input_dir) if os.path.isdir(f'{input_dir}/{x}')]
    include_subjects = []

    # Run each subject first level
    for subj in sorted(subjects):
        subj_dir = f'{output_dir}/SUBJECTS/{subj}'

        print(f'Checking {subj}')
        try:
            baseline_image = glob(f'{input_dir}/{subj}/FMRI/Baseline/d*.nii.gz')[0]
            baseline_mat = glob(f'{input_dir}/{subj}/FMRI/Baseline/*conditions.mat')[0]
            week5_image = glob(f'{input_dir}/{subj}/FMRI/Week5/d*.nii.gz')[0]
            week5_mat = glob(f'{input_dir}/{subj}/FMRI/Week5/*conditions.mat')[0]
        except:
            try:
                baseline_image = glob(f'{input_dir}/{subj}/PREPROC/{subj}/FMRI/Baseline/d*.nii.gz')[0]
                subj_mat = glob(f'{input_dir}/{subj}/PREPROC/{subj}/FMRI/Baseline/*conditions.mat')[0]
                week5_image = glob(f'{input_dir}/{subj}/PREPROC/{subj}/FMRI/Week5/d*.nii.gz')[0]
                week5_mat = glob(f'{input_dir}/{subj}/PREPROC/{subj}/FMRI/Week5/*conditions.mat')[0]
            except Exception as err:
                print(f'failed to load subject:{subj}:{err}')
                continue

        # Found everything so include this subject
        include_subjects.append(subj)

        if os.path.exists(subj_dir):
            print(f'skipping, exists:{subj_dir}')
            continue

        print(f'Running:{subj}')
        _run_subject(baseline_image, baseline_mat, week5_image, week5_mat, subj_dir, roi_dir)

    # Save subject list
    _write_subjects(include_subjects, f'{output_dir}/subjects.txt')
